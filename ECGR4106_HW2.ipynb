{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e7bfbd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ECGR 4106\n",
    "# HW 2\n",
    "# Trevor Goad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc1bbcc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "552b357a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dfb4d22c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>area</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>stories</th>\n",
       "      <th>mainroad</th>\n",
       "      <th>guestroom</th>\n",
       "      <th>basement</th>\n",
       "      <th>hotwaterheating</th>\n",
       "      <th>airconditioning</th>\n",
       "      <th>parking</th>\n",
       "      <th>prefarea</th>\n",
       "      <th>furnishingstatus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13300000</td>\n",
       "      <td>7420</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>furnished</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12250000</td>\n",
       "      <td>8960</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>furnished</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12250000</td>\n",
       "      <td>9960</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>semi-furnished</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12215000</td>\n",
       "      <td>7500</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>3</td>\n",
       "      <td>yes</td>\n",
       "      <td>furnished</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11410000</td>\n",
       "      <td>7420</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>2</td>\n",
       "      <td>no</td>\n",
       "      <td>furnished</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      price  area  bedrooms  bathrooms  stories mainroad guestroom basement  \\\n",
       "0  13300000  7420         4          2        3      yes        no       no   \n",
       "1  12250000  8960         4          4        4      yes        no       no   \n",
       "2  12250000  9960         3          2        2      yes        no      yes   \n",
       "3  12215000  7500         4          2        2      yes        no      yes   \n",
       "4  11410000  7420         4          1        2      yes       yes      yes   \n",
       "\n",
       "  hotwaterheating airconditioning  parking prefarea furnishingstatus  \n",
       "0              no             yes        2      yes        furnished  \n",
       "1              no             yes        3       no        furnished  \n",
       "2              no              no        2      yes   semi-furnished  \n",
       "3              no             yes        3      yes        furnished  \n",
       "4              no             yes        2       no        furnished  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing = pd.DataFrame(pd.read_csv(\"Housing.csv\")) \n",
    "\n",
    "housing.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2634336",
   "metadata": {},
   "outputs": [],
   "source": [
    "varlist =  ['mainroad', 'guestroom', 'basement', 'hotwaterheating', 'airconditioning', 'prefarea']\n",
    " \n",
    "# Defining the map function \n",
    "def binary_map(x): \n",
    "    return x.map({'yes': 1, \"no\": 0}) \n",
    " \n",
    "# Applying the function to the housing list \n",
    "housing[varlist] = housing[varlist].apply(binary_map)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "normalScaler = MinMaxScaler()\n",
    "standardScaler = StandardScaler()\n",
    "\n",
    "housing = housing.iloc[:, [0,1,2,3,4,10]]\n",
    "housing = normalScaler.fit_transform(housing)\n",
    "\n",
    "X = housing[:, [1,2,3,4,5]]\n",
    "Y = housing[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95a4bfc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the Data into Training and Testing Sets \n",
    "from sklearn.model_selection import train_test_split \n",
    " \n",
    "np.random.seed(0) \n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.20, random_state = 413)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d0015b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "t_u_train = X_train\n",
    "t_u_test = X_test\n",
    "t_c_train = Y_train\n",
    "t_c_test = Y_test\n",
    "\n",
    "t_u_train = torch.FloatTensor(t_u_train)\n",
    "t_u_test = torch.FloatTensor(t_u_test)\n",
    "t_c_train = torch.FloatTensor(t_c_train)\n",
    "t_c_test = torch.FloatTensor(t_c_test)\n",
    "\n",
    "t_un_train = t_u_train.to(device)\n",
    "t_un_test = t_u_test.to(device)\n",
    "t_c_train = t_c_train.to(device)\n",
    "t_c_test = t_c_test.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "24ca1225",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(n_epochs, optimizer, model, loss_fn, t_u_train,\n",
    "                 t_u_val, t_c_train, t_c_val):\n",
    "    start = time.time()\n",
    "    for epoch in range(1, n_epochs+1):\n",
    "        t_p_train = model(t_u_train)\n",
    "        loss_train = loss_fn(t_p_train, t_c_train)\n",
    "        \n",
    "        t_p_val = model(t_u_val)\n",
    "        \n",
    "        loss_val = loss_fn(t_p_val, t_c_val)\n",
    "    \n",
    "        optimizer.zero_grad()\n",
    "        loss_train.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "        if epoch == 1 or epoch % 10 == 0:\n",
    "            print(f\"Epoch {epoch}, Training loss {loss_train.item():.4f},\"\n",
    "              f\" Validation loss {loss_val.item():.4f}\")\n",
    "    stop = time.time()\n",
    "    print(f\"Training time: {stop - start}s\")\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dceae9ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=5, out_features=8, bias=True)\n",
       "  (1): Tanh()\n",
       "  (2): Linear(in_features=8, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_model_1 = nn.Sequential(\n",
    "            nn.Linear(5, 8),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(8, 1))\n",
    "seq_model_1.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "50760045",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Training loss 0.0265, Validation loss 0.0337\n",
      "Epoch 10, Training loss 0.0265, Validation loss 0.0337\n",
      "Epoch 20, Training loss 0.0265, Validation loss 0.0337\n",
      "Epoch 30, Training loss 0.0265, Validation loss 0.0336\n",
      "Epoch 40, Training loss 0.0264, Validation loss 0.0336\n",
      "Epoch 50, Training loss 0.0264, Validation loss 0.0335\n",
      "Epoch 60, Training loss 0.0264, Validation loss 0.0335\n",
      "Epoch 70, Training loss 0.0264, Validation loss 0.0335\n",
      "Epoch 80, Training loss 0.0263, Validation loss 0.0334\n",
      "Epoch 90, Training loss 0.0263, Validation loss 0.0334\n",
      "Epoch 100, Training loss 0.0263, Validation loss 0.0334\n",
      "Epoch 110, Training loss 0.0263, Validation loss 0.0334\n",
      "Epoch 120, Training loss 0.0263, Validation loss 0.0333\n",
      "Epoch 130, Training loss 0.0263, Validation loss 0.0333\n",
      "Epoch 140, Training loss 0.0262, Validation loss 0.0333\n",
      "Epoch 150, Training loss 0.0262, Validation loss 0.0333\n",
      "Epoch 160, Training loss 0.0262, Validation loss 0.0333\n",
      "Epoch 170, Training loss 0.0262, Validation loss 0.0332\n",
      "Epoch 180, Training loss 0.0262, Validation loss 0.0332\n",
      "Epoch 190, Training loss 0.0262, Validation loss 0.0332\n",
      "Epoch 200, Training loss 0.0262, Validation loss 0.0332\n",
      "Training time: 1.7474849224090576s\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.SGD(seq_model_1.parameters(), lr=1e-3)\n",
    "\n",
    "training_loop(\n",
    "    n_epochs = 200,\n",
    "    optimizer = optimizer,\n",
    "    model = seq_model_1,\n",
    "    loss_fn = nn.MSELoss(),\n",
    "    t_u_train = t_un_train,\n",
    "    t_u_val = t_un_test,\n",
    "    t_c_train = t_c_train,\n",
    "    t_c_val = t_c_test)\n",
    "\n",
    "print('done')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8d8c2f15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=5, out_features=8, bias=True)\n",
       "  (1): Tanh()\n",
       "  (2): Linear(in_features=8, out_features=4, bias=True)\n",
       "  (3): Tanh()\n",
       "  (4): Linear(in_features=4, out_features=2, bias=True)\n",
       "  (5): Tanh()\n",
       "  (6): Linear(in_features=2, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_model_2 = nn.Sequential(\n",
    "            nn.Linear(5, 8),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(8, 4),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(4,2),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(2,1))\n",
    "seq_model_2.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0fdd843a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Training loss 0.0262, Validation loss 0.0332\n",
      "Epoch 10, Training loss 0.0262, Validation loss 0.0332\n",
      "Epoch 20, Training loss 0.0262, Validation loss 0.0332\n",
      "Epoch 30, Training loss 0.0261, Validation loss 0.0332\n",
      "Epoch 40, Training loss 0.0261, Validation loss 0.0331\n",
      "Epoch 50, Training loss 0.0261, Validation loss 0.0331\n",
      "Epoch 60, Training loss 0.0261, Validation loss 0.0331\n",
      "Epoch 70, Training loss 0.0261, Validation loss 0.0331\n",
      "Epoch 80, Training loss 0.0261, Validation loss 0.0331\n",
      "Epoch 90, Training loss 0.0261, Validation loss 0.0331\n",
      "Epoch 100, Training loss 0.0261, Validation loss 0.0331\n",
      "Epoch 110, Training loss 0.0261, Validation loss 0.0331\n",
      "Epoch 120, Training loss 0.0261, Validation loss 0.0331\n",
      "Epoch 130, Training loss 0.0261, Validation loss 0.0330\n",
      "Epoch 140, Training loss 0.0261, Validation loss 0.0330\n",
      "Epoch 150, Training loss 0.0261, Validation loss 0.0330\n",
      "Epoch 160, Training loss 0.0261, Validation loss 0.0330\n",
      "Epoch 170, Training loss 0.0261, Validation loss 0.0330\n",
      "Epoch 180, Training loss 0.0261, Validation loss 0.0330\n",
      "Epoch 190, Training loss 0.0261, Validation loss 0.0330\n",
      "Epoch 200, Training loss 0.0261, Validation loss 0.0330\n",
      "Training time: 0.19124221801757812s\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.SGD(seq_model_1.parameters(), lr=1e-3)\n",
    "\n",
    "training_loop(\n",
    "    n_epochs = 200,\n",
    "    optimizer = optimizer,\n",
    "    model = seq_model_1,\n",
    "    loss_fn = nn.MSELoss(),\n",
    "    t_u_train = t_un_train,\n",
    "    t_u_val = t_un_test,\n",
    "    t_c_train = t_c_train,\n",
    "    t_c_val = t_c_test)\n",
    "\n",
    "print('done')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1a962f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#problem 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e9bc10bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "data_path = './tmp/tensorflow/mnist/input_data'\n",
    "cifar10 = datasets.CIFAR10(data_path, train = True, download = True,\n",
    "                          transform=transforms.ToTensor())\n",
    "cifar10_val = datasets.CIFAR10(data_path, train = False, download = True,\n",
    "                              transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f25aed98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.4942, 0.4851, 0.4504]), tensor([0.2467, 0.2429, 0.2616]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs = torch.stack([img_t for img_t, _ in cifar10_val], dim = 3)\n",
    "imgs.view(3, -1).mean(dim=1), imgs.view(3, -1).std(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9e9dc963",
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar10 = datasets.CIFAR10(data_path, train = True, download = False,\n",
    "                           transform=transforms.Compose([\n",
    "                               transforms.ToTensor(),\n",
    "                               transforms.Normalize((0.4914, 0.4822, 0.4465),\n",
    "                                                   (0.2470, 0.2435, 0.2616))\n",
    "                           ]))\n",
    "\n",
    "cifar10_val = datasets.CIFAR10(data_path, train = False, download = False,\n",
    "                           transform=transforms.Compose([\n",
    "                               transforms.ToTensor(),\n",
    "                               transforms.Normalize((0.4942, 0.4851, 0.4504),\n",
    "                                                   (0.2467, 0.2429, 0.2616))\n",
    "                           ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ce7246db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 1.852000\n",
      "Epoch: 25, Loss: 1.412853\n",
      "Epoch: 50, Loss: 1.106567\n",
      "Epoch: 75, Loss: 0.940826\n",
      "Epoch: 100, Loss: 0.606194\n",
      "Epoch: 125, Loss: 0.493893\n",
      "Epoch: 150, Loss: 0.328648\n",
      "Epoch: 175, Loss: 0.271958\n",
      "Epoch: 200, Loss: 0.181335\n",
      "Epoch: 225, Loss: 0.130539\n",
      "Epoch: 250, Loss: 0.110038\n",
      "Epoch: 275, Loss: 0.084745\n",
      "Epoch: 300, Loss: 0.060938\n",
      "Training time: 2974.2855870723724s\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "train_loader = torch.utils.data.DataLoader(cifar10, batch_size=64,\n",
    "                                            shuffle=True)\n",
    "\n",
    "model = nn.Sequential(\n",
    "        nn.Linear(3072, 512),\n",
    "        nn.Tanh(),\n",
    "        nn.Linear(512, 10),\n",
    "        nn.LogSoftmax(dim=1))\n",
    "model.to(device)\n",
    "\n",
    "learning_rate = 1e-2\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "loss_fn = nn.NLLLoss()\n",
    "\n",
    "n_epochs = 300\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for epoch in range(n_epochs+1):\n",
    "    for imgs, labels in train_loader:\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "        batch_size = imgs.shape[0]\n",
    "        outputs = model(imgs.view(batch_size, -1))\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    if (epoch % 25 ==0):\n",
    "        print(\"Epoch: %d, Loss: %f\" % (epoch, float(loss)))\n",
    "    \n",
    "stop = time.time()\n",
    "print(f\"Training time: {stop - start}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "21547480",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: %f 0.4695\n"
     ]
    }
   ],
   "source": [
    "val_loader = torch.utils.data.DataLoader(cifar10_val, batch_size=64,\n",
    "                                        shuffle=False)\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for imgs, labels in val_loader:\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "        batch_size = imgs.shape[0]\n",
    "        outputs = model(imgs.view(batch_size, -1))\n",
    "        _, predicted = torch.max(outputs, dim=1)\n",
    "        total += labels.shape[0]\n",
    "        correct += int((predicted == labels).sum())\n",
    "    \n",
    "print(\"Accuracy: %f\", correct/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61e084f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 2.063636\n",
      "Epoch: 25, Loss: 0.920640\n",
      "Epoch: 50, Loss: 0.019232\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "train_loader = torch.utils.data.DataLoader(cifar10, batch_size=64,\n",
    "                                            shuffle=True)\n",
    "\n",
    "model = nn.Sequential(\n",
    "        nn.Linear(3072, 2150),\n",
    "        nn.Tanh(),\n",
    "        nn.Linear(2150, 1120),\n",
    "        nn.Tanh(),\n",
    "        nn.Linear(1120, 512),\n",
    "        nn.Tanh(),\n",
    "        nn.Linear(512, 10),\n",
    "        nn.LogSoftmax(dim=1))\n",
    "model.to(device)\n",
    "\n",
    "learning_rate = 1e-2\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "loss_fn = nn.NLLLoss()\n",
    "\n",
    "n_epochs = 300\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for epoch in range(n_epochs+1):\n",
    "    for imgs, labels in train_loader:\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "        batch_size = imgs.shape[0]\n",
    "        outputs = model(imgs.view(batch_size, -1))\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    if (epoch % 25 ==0):\n",
    "        print(\"Epoch: %d, Loss: %f\" % (epoch, float(loss)))\n",
    "    \n",
    "stop = time.time()\n",
    "print(f\"Training time: {stop - start}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "70475216",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: %f 0.4806\n"
     ]
    }
   ],
   "source": [
    "val_loader = torch.utils.data.DataLoader(cifar10_val, batch_size=64,\n",
    "                                        shuffle=False)\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for imgs, labels in val_loader:\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "        batch_size = imgs.shape[0]\n",
    "        outputs = model(imgs.view(batch_size, -1))\n",
    "        _, predicted = torch.max(outputs, dim=1)\n",
    "        total += labels.shape[0]\n",
    "        correct += int((predicted == labels).sum())\n",
    "    \n",
    "print(\"Accuracy: %f\", correct/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7404f67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
